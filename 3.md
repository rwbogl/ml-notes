# Neurons and Neural Networks

## Neurons

- Hebb's Rule postulates that the relationship between neurons is determined by
  how often they fire simultaneously. This allows us to formulate our model of
  how neurons learn.

- Given MCP neurons, we can only modify the weights and the threshold. These
  are updated using the perceptron algorithm.

A positive weight from node A to node B indicates that positive inputs in A
generally imply B. A negative weight from A to B indicates that positive inputs
in A generally imply not B.

## Perceptrons

### Introduction

- Perceptrons are networks of MCP neurons, where there is a layer of inputs and
  a layer of MCP neurons. Every input is connected to every neuron in the
  network.

Weights are updated by punishing the weights that do poorly (mismatch the
target).

- Find nodes where $y_k \neq t_k$, and consider the positive weights.
- If $y_k > t_k$, then positive inputs are contributing too much.
- If $y_k < t_k$, then positive inputs are not contributing enough.

This method only works if we have a positive input. If we have a negative
input, then we need to do the opposite. For example, if $y_k > t_k$ and $x_k$
was negative, then the weight did not add enough value to $x_k$ to stop the
firing, so the weight must be increased. This rule is succinctly described by
$$\Delta w_{ik} = -(y_k - t_k) x_i,$$ where $\Delta w_{ik}$ is the amount of
change to weight $w_{ik}$, i.e. $w^{k + 1}_{ik} = w^k_{ik} + \Delta
w^{ik}_{ik}$. The following properties are easy to verify:

- If $y_k > t_k$ (misfire):
    - If $x_k > 0$, then the weight decreases. ($w_k x_k$ added too much.)
    - If $x_k < 0$, then the weight increases. ($w_k x_k$ did not take away
      enough.)
- If $y_k < t_k$ (should have fired):
    - If $x_k > 0$, then the weight increases. ($w_k x_k$ did not add enough.)
    - If $x_k < 0$, then the weight decreases. ($w_k x_k$ took away too much.)

The only remaining component is the learning rate, $\eta$. It is essentially
like a step size, i.e. how far we should step in the direction of the "correct"
descent.

### Perceptron Convergence Theorem

Amazingly, for some datasets, Perceptrons are guaranteed to learn them in
finite time. These datasets are called _linearly separable_, and to talk about
them, we need to discuss more about what the Perceptron is actually doing.

The weights of perceptrons define a _decision boundary_. If an input falls on
one side of the decision boundary, it it classified one way; if it falls on the
other side, the other way. This decision boundary is, in general, a hyperplane
defined by the equation $\vec{x}\vec{W}^T = 0$, where $\vec{W}$ is the weight
vector for a single perceptron.

A dataset is called _linearly separable_ if there exists a linear separator
that correctly classifies the dataset. More formally, if we can partition the
dataset into two disjoint classes $C_1$ and $C_2$, then the dataset is linearly
separable iff there exists some weight vector $\vec{W}$ such that $\vec{x}
\vec{W}^T \geq 0$ for all $\vec{x} \in C_1$, and $\vec{x} \vec{W}^T < 0$ for
all $\vec{x} \in C_2$.

The Perceptron Convergence Theorem states that, if a dataset is linearly
separable, then the Perceptron learning algorithm will find a linear separating
weight vector in finite time. That is, the Perceptron will be able to correctly
classify inputs based on which side of the boundary they fall on in finite
time.

### Convergence Time Estimate

The Perceptron Convergence theorem states that, given a linearly separable
dataset, the perceptron will learn a linear separator within $1/\gamma$
updates, where $\gamma$ is defined to be the distance from the linear separator
that the perceptron _will_ converge to and the datapoint closest to it.

As an approximation of $\gamma$, we can use $d$, where $d$ is half of the
smallest distance between any two points of opposite classes. Then, we define
$T' = 1/d^2$, which is _usually_^[He says, using proof by intimidation.] less
than $T$. That is, we we create a convergence time estimate $T'$ such that $T >
T'$.

### Perceptron Linear Regression

Essentially, we use calculus to find the "weight" vector $\vec{\beta}$ that
minimizes the sum of squared errors $$\sum_{k = 0}^N (t_k - y_k)^2 = \sum_{k =
0}^N (t_k - \sum_{j = 0}^m \beta_j x_j).$$

Perceptrons try to draw lines _between_ data, to classify points. Linear
regression tries to draw lines _through_ data, to match the points' class
values.
