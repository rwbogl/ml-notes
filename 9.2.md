# The Levenberg-Marquardt Algorithm

(The text does a terrible job of explaining where equations and final statement
of problems come from. In particular, the jump to Equations (9.16) and (9.17)
is abrupt. [Wolfram's
MathWorld](http://mathworld.wolfram.com/Levenberg-MarquardtMethod.html) was a
great help here.)

The Levenberg-Marquardt Algorithm (LMA) is a line-search trust-region algorithm
used to minimize linear _and_ non-linear least-square problems. That is, it
seeks to minimize functions of the form $$f(\vec{x}) = \frac{1}{2} \sum_{k =
1}^n r_k(\vec{x})^2 = \frac{1}{2} | \vec{r}(\vec{x}) |^2.$$ As a _line search_
algorithm, it has a particular way of determining the direction to search in,
involving Jacobians and linear least-square methods. Overall, it is a _trust
region_ algorithm because it makes assumptions about the function being
minimized within a particular region, called a _trust region_.

## Search Direction

Recall that a line search algorithm works by choosing an initial guess
$\vec{x}_0$, then defining each later point by the equation $$\vec{x}_{n + 1} =
\vec{x}_n + \alpha_n \vec{p}_n,$$ where $\alpha_n$ is the search length and
$\vec{p}_n$ is the search direction.

LMA sets $\alpha_n = 1$ and then chooses $\vec{p}$ in a way that blends two
other methods: gradient descent and the Gauss-Newton method. Gradient descent
chooses the direction $\vec{d}_n = -\nabla f(x_n)$, which ends up being defined
by $$\nabla f(x_n)_j = \sum_{k = 1}^n r_k(\vec{x}) \frac{\partial r_k}{\partial
x_j}.$$ If we let $J$ denote the Jacobian of $\vec{r}$, then this gradient
works out to be $$\nabla f(\vec{x}) = J^T \vec{r}.$$ Jumping straight to
Jacobians, the Gauss-Newton method direction is $$\vec{g} = (J^T J)^{-1} J^T
\vec{r}.$$ (For technical reasons, i.e. $J$ may not be square, this inverse
does not always simplify nicely.) Finally, LMA chooses the direction $$\vec{l}
= -(J^T J + \lambda I)^{-1} J^T \vec{r},$$ where the parameter $\lambda$ is a
"dampening" parameter and $I$ is the identity matrix. According to [smart
people](http://people.duke.edu/~hpgavin/ce281/lm.pdf), if $\lambda$ is large,
then this direction is approximately the same as gradient descent; if it is
small, then the direction is approximately the same as Gauss-Newton.

The trust region as a region where we assume that the function $f$ being
minimized is roughly quadratic. This is an approximating assumption LMA makes
that throws away terms of the taylor expansion of $f$. The size of the trust
region is roughly inversely proportional to the value $\lambda$. The "trust
region growing" means that $\lambda$ decreases, or that we are more comfortable
choosing the more aggressive Gauss-Newton direction. The "trust region
shrinking" means that $\lambda$ increases, or that we are more cautious and
prefer the standard gradient descent direction.

## Algorithmic Sketch

The only head-scratching part in this is evaluating the quadratic trust region
assumption. If a function is quadratic, then we can closely predict its change.
If this prediction is off, then we shrink our trust region. If it is
acceptable, then we change nothing. If it is good, then we increase our trust
region.

(This is a good-faith effort to combine the strange text algorithm with its
online implementation.)

- Choose an initial guess $\vec{x}_0$ for the minimum of $f(\vec{x})$.

- While $J^T \vec{r} > \epsilon > 0$ and a maximum number of iterations is not
  exceeeded:
    - repeat until a new point is found
        - Solve $\vec{l} = -(J^T J + \lambda I)^{-1} J^T \vec{r}$ using linear
          least-squares methods.

        - Set $\vec{x}_{n + 1} = \vec{x}_n + \vec{l}$.

        - Evaluate how well our trust region assumption is working.
            - actual = $|f(\vec{x}_{n + 1}) - f(\vec{x}_n)|$
            - predicted = $\nabla f(\vec{x}_n) \cdot (\vec{x}_{n + 1} -
              \vec{x})$ (note the probable typo on page 196)
            - set $\rho =$ actual/predicted

        - If $0 < \rho < 0.25$:
            - accept new step
        - If $0.25 < \rho$:
            - accept new step
            - increase trust region (decrease $\lambda$)
        - Else ($\rho \leq 0$ (?)[^negative]):
            - reject new step
            - reduce trust region (increase $\lambda$)

[^negative]: This doesn't make much sense. This is negative only if "predicted"
is negative, which doesn't mean anything about the relative magnitude of
errors. It is difficult to parse the author's implementation, since they apply
`np.linalg.norm`, which I believe makes everything positive, then makes the
same positive/negative check.
